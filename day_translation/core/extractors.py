from typing import List, Tuple, Set, Dict, Optional
import logging
import os
import xml.etree.ElementTree as ET
from pathlib import Path
from functools import lru_cache
import asyncio
try:
    import aiofiles
    AIOFILES_AVAILABLE = True
except ImportError:
    AIOFILES_AVAILABLE = False
    logging.warning("aiofiles æœªå®‰è£…ï¼Œå°†ä½¿ç”¨åŒæ­¥æ–¹å¼è¯»å–æ–‡ä»¶")

from ..utils.config import TranslationConfig
from ..utils.utils import get_language_folder_path
from ..utils.fields import extract_translatable_fields
from .exporters import export_keyed, export_definjected

CONFIG = TranslationConfig()

# ğŸ”§ åˆå¹¶ï¼šå°† EnhancedExtractor åŠŸèƒ½æ•´åˆåˆ°ç»Ÿä¸€æå–å™¨
class UnifiedExtractor:
    """ç»Ÿä¸€çš„å†…å®¹æå–å™¨ - åˆå¹¶åŸºç¡€å’Œå¢å¼ºåŠŸèƒ½"""
    
    def __init__(self, mod_dir: str, filter_mode: str = "standard", config_file: str = None):
        """
        åˆå§‹åŒ–æå–å™¨
        
        Args:
            mod_dir: æ¨¡ç»„ç›®å½•
            filter_mode: è¿‡æ»¤æ¨¡å¼
            config_file: é…ç½®æ–‡ä»¶è·¯å¾„ï¼ˆå¯é€‰ï¼‰
        """
        self.mod_dir = Path(mod_dir)
        self._xml_cache: Dict[str, List[Tuple[str, str, str, str]]] = {}
        
        # ğŸ”§ å»¶è¿ŸåŠ è½½è¿‡æ»¤å™¨ï¼Œé¿å…å¾ªç¯å¯¼å…¥
        self._content_filter = None
        self.filter_mode = filter_mode
        self.config_file = config_file
    
    @property
    def content_filter(self):
        """å»¶è¿Ÿåˆå§‹åŒ–è¿‡æ»¤å™¨"""
        if self._content_filter is None:
            from .filters import ContentFilter
            self._content_filter = ContentFilter(self.filter_mode, self.config_file)
        return self._content_filter
    
    def extract_keyed_translations(self, keyed_dir: str, progress_callback=None) -> List[Tuple[str, str, str, str]]:
        """æå– Keyed ç¿»è¯‘ - ç»Ÿä¸€ç‰ˆæœ¬"""
        translations = []
        xml_files = list(Path(keyed_dir).rglob("*.xml"))
        
        if progress_callback:
            progress_callback(f"æ‰«æ {len(xml_files)} ä¸ª XML æ–‡ä»¶...")
        
        for i, xml_file in enumerate(xml_files, 1):
            if progress_callback and i % 10 == 0:
                progress_callback(f"è¿›åº¦: {i}/{len(xml_files)}")
                
            try:
                # ğŸ”§ ä½¿ç”¨ç¼“å­˜æœºåˆ¶
                file_key = str(xml_file)
                if file_key in self._xml_cache:
                    translations.extend(self._xml_cache[file_key])
                    continue
                
                tree = ET.parse(xml_file)
                root = tree.getroot()
                
                file_translations = []
                for elem in root:
                    if isinstance(elem.tag, str) and elem.text:
                        if self.content_filter.is_translatable(elem.tag, elem.text, "Keyed"):
                            translation = (elem.tag, elem.text.strip(), elem.tag, str(xml_file))
                            file_translations.append(translation)
                            translations.append(translation)
                        else:
                            logging.debug(f"è¿‡æ»¤éç¿»è¯‘å†…å®¹: {elem.tag}={elem.text}")
                
                self._xml_cache[file_key] = file_translations
                
            except ET.ParseError as e:
                logging.error(f"XMLè§£æå¤±è´¥: {xml_file}: {e}")
                if progress_callback:
                    progress_callback(f"âŒ {xml_file.name}: XML è§£æå¤±è´¥")
            except OSError as e:
                logging.error(f"æ–‡ä»¶è¯»å–å¤±è´¥: {xml_file}: {e}")
                if progress_callback:
                    progress_callback(f"âŒ {xml_file.name}: æ–‡ä»¶è¯»å–å¤±è´¥")
        
        return translations
    
    def extract_defs_translations(self, preview_limit: int = 1000) -> List[Tuple[str, str, str, str]]:
        """ä» Defs ç›®å½•æå–ç¿»è¯‘ - å§”æ‰˜ç»™ preview_translatable_fields"""
        # ğŸ”§ ä¿®å¤å‚æ•°ä¼ é€’é—®é¢˜
        return preview_translatable_fields(
            mod_dir=str(self.mod_dir),
            preview=preview_limit,
            facade=self  # ä¼ é€’è‡ªèº«è€Œä¸æ˜¯ self
        )
    
    def is_translatable_content(self, tag: str, text: str, context: str = "") -> bool:
        """ğŸ”§ ä¿®å¤æ–¹æ³•åå’Œå…¼å®¹æ€§"""
        return self.content_filter.is_translatable(tag, text, context)

# ğŸ”§ ä¿æŒå‘åå…¼å®¹çš„å‡½æ•°æ¥å£
def extract_keyed_translations(keyed_dir: str, content_filter=None) -> List[Tuple[str, str, str, str]]:
    """æå– Keyed ç¿»è¯‘ - å‘åå…¼å®¹æ¥å£"""
    if content_filter:
        # ä½¿ç”¨ä¼ å…¥çš„è¿‡æ»¤å™¨
        extractor = UnifiedExtractor(str(Path(keyed_dir).parent.parent.parent))
        extractor._content_filter = content_filter
        return extractor.extract_keyed_translations(keyed_dir)
    else:
        # ä½¿ç”¨åŸºæœ¬è¿‡æ»¤
        translations = []
        xml_files = list(Path(keyed_dir).rglob("*.xml"))
        
        for xml_file in xml_files:
            try:
                tree = ET.parse(xml_file)
                root = tree.getroot()
                
                for elem in root:
                    if isinstance(elem.tag, str) and elem.text:
                        if _basic_translatable_check(elem.tag, elem.text):
                            translations.append((elem.tag, elem.text.strip(), elem.tag, str(xml_file)))
                            
            except ET.ParseError as e:
                logging.error(f"XMLè§£æå¤±è´¥: {xml_file}: {e}")
            except OSError as e:
                logging.error(f"æ–‡ä»¶è¯»å–å¤±è´¥: {xml_file}: {e}")
        
        return translations

@lru_cache(maxsize=1)
def preview_translatable_fields(
    mod_dir: str,
    preview: int = 100,
    facade=None
) -> List[Tuple[str, str, str, str]]:
    """é¢„è§ˆå¯ç¿»è¯‘å­—æ®µ - ç®€åŒ–ç‰ˆæœ¬"""
    results = []
    defs_dir = Path(mod_dir) / "Defs"
    
    if not defs_dir.exists():
        logging.warning(f"Defs ç›®å½•ä¸å­˜åœ¨: {defs_dir}")
        return results
    
    xml_files = list(defs_dir.rglob("*.xml"))
    processed_count = 0
    
    for xml_file in xml_files:
        if processed_count >= preview:
            break
            
        try:
            tree = ET.parse(xml_file)
            root = tree.getroot()
            
            for def_elem in root.findall('.//Defs/*'):
                if processed_count >= preview:
                    break
                
                def_name_elem = def_elem.find('defName')
                if def_name_elem is None or not def_name_elem.text:
                    continue
                
                def_name = def_name_elem.text.strip()
                def_type = def_elem.tag
                
                for field_name, field_text in _extract_translatable_fields_recursive(def_elem):
                    if processed_count >= preview:
                        break
                    
                    # ğŸ”§ ç®€åŒ–è¿‡æ»¤é€»è¾‘
                    filter_passed = False
                    if facade and hasattr(facade, 'content_filter'):
                        filter_passed = facade.content_filter.is_translatable(field_name, field_text, "Defs")
                    elif facade and hasattr(facade, '_is_translatable_content'):
                        filter_passed = facade._is_translatable_content(field_name, field_text, "Defs")
                    else:
                        filter_passed = _basic_translatable_check(field_name, field_text)
                    
                    if filter_passed:
                        key = f"{def_type}/{def_name}.{field_name}"
                        results.append((key, field_text, field_name, str(xml_file)))
                        processed_count += 1
                    
        except Exception as e:
            logging.error(f"æ–‡ä»¶å¤„ç†å¤±è´¥ {xml_file}: {e}")
    
    return results

def _extract_translatable_fields_recursive(element: ET.Element, prefix: str = "") -> List[Tuple[str, str]]:
    """é€’å½’æå– - ç®€åŒ–ç‰ˆæœ¬"""
    results = []
    translatable_fields = {
        'label', 'description', 'labelShort', 'descriptionShort',
        'title', 'text', 'message', 'tooltip', 'baseDesc',
        'skillDescription', 'backstoryDesc', 'jobString',
        'gerundLabel', 'verb', 'deathMessage', 'summary',
        'note', 'flavor', 'quote', 'caption'
    }
    
    for child in element:
        if not isinstance(child.tag, str):
            continue
            
        field_name = f"{prefix}.{child.tag}" if prefix else child.tag
        
        if child.tag.lower() in translatable_fields and child.text and child.text.strip():
            results.append((field_name, child.text.strip()))
        
        if len(child) > 0 and len(field_name.split('.')) < 4:  # é™åˆ¶æ·±åº¦
            results.extend(_extract_translatable_fields_recursive(child, field_name))
    
    return results

def _basic_translatable_check(tag: str, text: str) -> bool:
    """åŸºæœ¬æ£€æŸ¥ - æœ€ç®€ç‰ˆæœ¬"""
    if not text or len(text.strip()) < 2:
        return False
    
    blacklist = {'defName', 'id', 'cost', 'damage', 'x', 'y', 'z'}
    if tag.lower() in blacklist:
        return False
    
    if text.isdigit():
        return False
    
    return True

# ğŸ”§ ä¿æŒå‘åå…¼å®¹çš„å…¶ä»–å‡½æ•°
def extract_key(
    mod_dir: str,
    export_dir: str,
    language: str = CONFIG.default_language,
    source_language: str = CONFIG.source_language
) -> None:
    """æå– Keyed ç¿»è¯‘"""
    logging.info(f"æå– Keyed ç¿»è¯‘: mod_dir={mod_dir}, export_dir={export_dir}")
    try:
        export_keyed(
            mod_dir=mod_dir,
            export_dir=export_dir,
            language=language,
            source_language=source_language
        )
    except (ET.ParseError, OSError) as e:
        logging.error(f"æå– Keyed ç¿»è¯‘å¤±è´¥: {e}")

def extract_definjected_from_defs(
    mod_dir: str,
    export_dir: str,
    language: str = CONFIG.default_language
) -> None:
    """ä» Defs æå– DefInjected ç¿»è¯‘"""
    selected_translations = preview_translatable_fields(mod_dir, preview=CONFIG.preview_translatable_fields)
    if not selected_translations:
        if CONFIG.preview_translatable_fields:
            print("æœªé€‰æ‹©å­—æ®µï¼Œè·³è¿‡ç”Ÿæˆã€‚")
        return
    try:
        export_definjected(
            mod_dir=mod_dir,
            export_dir=export_dir,
            selected_translations=selected_translations,
            language=language
        )
    except (ET.ParseError, OSError) as e:
        logging.error(f"æå– DefInjected ç¿»è¯‘å¤±è´¥: {e}")

def extract_translate(
    mod_dir: str,
    export_dir: str,
    language: str = CONFIG.default_language,
    source_language: str = CONFIG.source_language
) -> None:
    """æå–æ‰€æœ‰ç¿»è¯‘"""
    from .exporters import handle_extract_translate
    try:
        handle_extract_translate(
            mod_dir=mod_dir,
            export_dir=export_dir,
            language=language,
            source_language=source_language,
            extract_definjected_from_defs=extract_definjected_from_defs
        )
    except (ET.ParseError, OSError) as e:
        logging.error(f"æå–ç¿»è¯‘å¤±è´¥: {e}")

# ğŸ”§ ç®€åŒ–çš„åŒæ­¥æ‰«æå‡½æ•°
def scan_defs_sync(defs_path: Path) -> List[Tuple[str, str, str, str]]:
    """åŒæ­¥æ‰«æ Defs ç›®å½• - ç®€åŒ–ç‰ˆ"""
    all_translations = []
    for file in defs_path.rglob("*.xml"):
        translations = read_xml_sync(file)
        all_translations.extend(translations)
    return all_translations

def read_xml_sync(file: Path) -> List[Tuple[str, str, str, str]]:
    """åŒæ­¥è¯»å– XML æ–‡ä»¶ - ç®€åŒ–ç‰ˆ"""
    translations = []
    try:
        tree = ET.parse(file)
        def_nodes = tree.findall(".//*[defName]")
        for def_node in def_nodes:
            def_type = def_node.tag
            def_name = def_node.find("defName")
            if def_name is None or not def_name.text:
                continue
            def_name_text = def_name.text
            fields = extract_translatable_fields(def_node)
            for field_path, text, tag in fields:
                clean_path = field_path
                if clean_path.startswith(f"{def_type}."):
                    clean_path = clean_path[len(def_type) + 1:]
                full_path = f"{def_type}/{def_name_text}.{clean_path}"
                translations.append((full_path, text, tag, str(file)))
    except Exception as e:
        logging.error(f"å¤„ç†æ–‡ä»¶å¤±è´¥ {file}: {e}")
    return translations

# ğŸ”§ å¼‚æ­¥åŠŸèƒ½ï¼ˆå¯é€‰ï¼Œå¦‚æœéœ€è¦é«˜æ€§èƒ½ï¼‰
async def read_xml(file: Path) -> List[Tuple[str, str, str, str]]:
    """å¼‚æ­¥è¯»å–å¹¶è§£æ XML æ–‡ä»¶"""
    translations = []
    try:
        if AIOFILES_AVAILABLE:
            async with aiofiles.open(file, encoding="utf-8") as f:
                content = await f.read()
        else:
            with open(file, encoding="utf-8") as f:
                content = f.read()
        
        tree = ET.fromstring(content)
        def_nodes = tree.findall(".//*[defName]")
        for def_node in def_nodes:
            def_type = def_node.tag
            def_name = def_node.find("defName")
            if def_name is None or not def_name.text:
                continue
            def_name_text = def_name.text
            fields = extract_translatable_fields(def_node)
            for field_path, text, tag in fields:
                clean_path = field_path
                if clean_path.startswith(f"{def_type}."):
                    clean_path = clean_path[len(def_type) + 1:]
                full_path = f"{def_type}/{def_name_text}.{clean_path}"
                translations.append((full_path, text, tag, str(file)))
    except Exception as e:
        logging.error(f"å¼‚æ­¥å¤„ç†å¤±è´¥ {file}: {e}")
    return translations

async def scan_defs(defs_path: Path) -> List[Tuple[str, str, str, str]]:
    """å¼‚æ­¥æ‰«æ Defs ç›®å½•"""
    all_translations = []
    tasks = [read_xml(file) for file in defs_path.rglob("*.xml")]
    for task in await asyncio.gather(*tasks, return_exceptions=True):
        if isinstance(task, Exception):
            logging.error(f"å¼‚æ­¥ä»»åŠ¡å¤±è´¥: {task}")
        else:
            all_translations.extend(task)
    return all_translations

# ğŸ—‘ï¸ å‘åå…¼å®¹ï¼šæä¾› EnhancedExtractor åˆ«å
EnhancedExtractor = UnifiedExtractor